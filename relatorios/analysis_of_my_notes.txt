
=== DIRETÓRIO: analysis_of_my_notes ===


=== DIRETÓRIO: analysis_of_my_notes\Data ===

--- ARQUIVO: analysis_of_my_notes\README.md ---
# Analysis of my Notes
Este repositório é uma análise real dos meus estudos.  
Ele se baseia na **coleta**, **limpeza** e **análise** das notas dos meus estudos no programa [Obsidian](https://obsidian.md/).

#### O que é o Obsidian?
O Obsidian é um programa que lê arquivos `.md` (Markdown) e cria todo um ecossistema onde as notas ficam organizadas.

## Inspiração
Inspirei-me em outro programa que desenvolvi, chamado [TXT_to_OBS](), que simplesmente transformava todos os arquivos e pastas em um único TXT grande. Esse arquivo continha todas as notas e os caminhos para chegar até elas, partindo da raiz do sistema.  
A partir disso, decidi criar algo mais útil, realizando uma análise que me ajudasse a identificar:
- Notas com problemas;
- Notas mal organizadas;
- Notas com muitas ou poucas palavras.

## Organização do Projeto
- **Data**: Contém o CSV com os dados limpos e as novas características criadas.  
- **Notebooks**: Contém os notebooks onde as análises são realizadas.  
- **Src**: Contém o código responsável pela limpeza e engenharia de características.  

## Próximos Passos
- [x] Pegar os dados.
- [x] Transformar os dados em um DataFrame.
- [x] Limpar os dados.
- [x] Adicionar colunas úteis (`Palavras/Link`, `cont_tags`, `quão_escondido`).
- [x] Salvar os dados limpos em CSV.
- [x] Criar um histograma.
- [x] Analisar os arquivos com poucos links/tags.
- [ ] Analisar os arquivos com déficit de links/tags que possuem muitas ou poucas palavras.
- [ ] Por tags nos que não tem levando em conta o caminho.
- [ ] Criar um grafico de todas os dias q estudei como o ![alt text](image-1.png)
#### ideias
N-gramas das palavras mais vistas por tags
![Nuvem de palavras](image.png)
## Contato
- [GitHub](https://github.com/JhonAI13)  
- [LinkedIn](https://www.linkedin.com/in/jonathas-rocha/)  
- Discord: `#jonathas_martins`



=== DIRETÓRIO: analysis_of_my_notes\notebooks ===

--- ARQUIVO: analysis_of_my_notes\notebooks\01Analize.ipynb (sem output) ---
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(r\"C:\\Users\\jonat\\Documents\\GitHub\\analysis_of_my_notes\\Data\\clean_data.csv\")\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.hist(df['Contagem de Palavras'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.hist(df['Links'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "não_tem_tag = df[df['Tags']==\"[]\"]\n",
        "print(f' Tem {df.shape[0] - não_tem_tag.shape[0]} arquivos com tags, de {df.shape[0]} arquivos, sedo os {não_tem_tag.shape[0]} sem tags.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "não_tem_link = df[df['Links']== 0]\n",
        "print(f' Tem {df.shape[0] - não_tem_link.shape[0]} arquivos com Links, de {df.shape[0]} arquivos, sedo os {não_tem_link.shape[0]} sem Links.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sem_link_tag = pd.merge(não_tem_link, não_tem_tag, how='inner')\n",
        "print(f'Existem {sem_link_tag.shape[0]} notas que não tem link e tag.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sem_link_tag[sem_link_tag['Palavras/Link'] < 1].sort_values('Palavras/Link')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tags = {\"Conceito\": \"Conceito\", 'Comando': \"Comando\",'Gráfico': 'Matplotlib', 'Estatística':'Estatística','Excel':'Excel','Artigo':'Artigo', 'Livros':'Livros','Videos': 'Videos', 'Ideia': 'Ideia','Anki':'Anki', 'Inglês': 'Inglês', 'Grammar': 'Grammar', 'Eletrônica':'Eletrônica','Componentes':'Componentes',\n",
        "        \"Programação\": ['Comando', 'Python', 'Desenvolvimento', 'SQL'],\n",
        "        'Biblioteca': ['Numpy','Matplotlib', 'Scipy'],\n",
        "        'Tabela': ['Numpy', 'Excel', 'Pandas']}\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}


=== DIRETÓRIO: analysis_of_my_notes\src ===

--- ARQUIVO: analysis_of_my_notes\src\main.py ---
import pandas as pd
import numpy as np

# Carrega o arquivo CSV em um DataFrame do pandas
df = pd.read_csv(r'C:\Users\jonat\Documents\GitHub\OBS-to-TXT\notas_organizadas.csv')

# Converte a coluna 'Data da Última Modificação' para o tipo datetime, mantendo apenas a data (sem hora)
df['Data da Última Modificação'] = pd.to_datetime(df['Data da Última Modificação']).dt.date
# Trata erros de conversão em 'Data da Última Modificação', substituindo valores inválidos por NaT (Not a Time)
df['Data da Última Modificação'] = pd.to_datetime(df['Data da Última Modificação'], errors='coerce')

# Converte a coluna 'Data da Nota' para datetime, substituindo valores inválidos por NaT
df['Data da Nota'] = pd.to_datetime(df['Data da Nota'], errors='coerce')

# Substitui valores na coluna 'Tags' que começam com 'data:' por NaN
df['Tags'] = df['Tags'].apply(lambda x: np.nan if isinstance(x, str) and x.startswith('data:') else x)

# Remove o símbolo '#' das tags
df['Tags'] = df['Tags'].str.replace(r'#', '', regex=True)
# Remove aspas '"' das tags
df['Tags'] = df['Tags'].str.replace(r'"', '', regex=True)
# Divide as tags em listas, separando por espaços, e remove espaços extras ao redor das palavras
df['Tags'] = df['Tags'].apply(lambda x: [tag.strip() for tag in str(x).split()] if pd.notna(x) else [])

# Função para agregar todos os valores de uma coluna que contém listas
def obter_valores_lista(df, coluna):
    valores = []  # Inicializa uma lista vazia para armazenar os valores
    for lista in df[coluna]:
        valores.extend(lista)  # Adiciona todos os valores da lista à lista 'valores'
    return valores

# Chama a função para obter uma lista de todas as tags únicas na coluna 'Tags'
todos_valores = obter_valores_lista(df, 'Tags')
list(set(todos_valores))  # Remove duplicatas da lista 'todos_valores'

# Cria uma nova coluna com a razão entre a classificação de 'Contagem de Palavras' e 'Links'
df['Palavras/Link'] = df['Contagem de Palavras'].rank(method='average', ascending=False) / df['Links'].rank(method='average', ascending=False)

# Ordena o DataFrame com base na coluna 'Palavras/Link' em ordem crescente
df.sort_values("Palavras/Link")

# Adiciona uma nova coluna que conta o número de tags para cada entrada
df['cont_tags'] = df['Tags'].apply(lambda x: len(x) if isinstance(x, list) else 0)

# Cria uma coluna para medir o quão "escondida" uma nota está com base no número de barras invertidas no caminho
df['quão_escondido'] = df['Caminho da Nota'].str.count(r"\\")

# Salva o DataFrame processado em um novo arquivo CSV
df.to_csv(r"C:\Users\jonat\Documents\GitHub\analysis_of_my_notes\Data\clean_data.csv", index=False, encoding='utf-8')


